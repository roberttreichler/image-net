{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#from IPython.display import Image, display\n",
    "\n",
    "import PIL\n",
    "#from PIL import Image\n",
    "\n",
    "# Functions and classes for loading and using the Inception model.\n",
    "#import inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On the kaggle notebook\n",
    "# we only take the first 2000 from the training set\n",
    "# and only the first 1000 from the test set\n",
    "# REMOVE [0:2000] and [0:1000] when running locally\n",
    "train_image_file_names = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "test_image_file_names = [TEST_DIR+i for i in os.listdir(TEST_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Slow, yet simple implementation with tensorflow\n",
    "# could be rewritten to be much faster\n",
    "# (which is not really needed as it takes less than 5 minutes on my laptop)\n",
    "def decode_image(image_file_names, resize_func=None):\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        file_name = tf.placeholder(dtype=tf.string)\n",
    "        file = tf.read_file(file_name)\n",
    "        image = tf.image.decode_jpeg(file)\n",
    "        if resize_func != None:\n",
    "            image = resize_func(image)\n",
    "    \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()   \n",
    "        for i in range(len(image_file_names)):\n",
    "            images.append(session.run(image, feed_dict={file_name: image_file_names[i]}))\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print('Images processed: ',i+1)\n",
    "        \n",
    "        session.close()\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = decode_image(train_image_file_names)\n",
    "test_images = decode_image(test_image_file_names)\n",
    "all_images = train_images + test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WIDTH=64\n",
    "HEIGHT=64\n",
    "resize_func = lambda image: tf.image.resize_image_with_crop_or_pad(image, HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_train_images = decode_image(train_image_file_names, resize_func=resize_func)\n",
    "processed_test_images = decode_image(test_image_file_names, resize_func=resize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chech the shapes\n",
    "print(np.shape(processed_train_images))\n",
    "print(np.shape(processed_test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#setup a standard image size; this will distort some images but will get everything into the same shape\n",
    "STANDARD_SIZE = (64, 64)\n",
    "def img_to_matrix(filename, verbose=False):\n",
    "    \"\"\"\n",
    "    takes a filename and turns it into a numpy array of RGB pixels\n",
    "    \"\"\"\n",
    "    img = PIL.Image.open(filename)\n",
    "    if verbose==True:\n",
    "        print (\"changing size from %s to %s\" % (str(img.size), str(STANDARD_SIZE)))\n",
    "    img = img.resize((250,250),PIL.Image.ANTIALIAS)\n",
    "    img = list(img.getdata())\n",
    "    #img = map(list, img)\n",
    "    img = [list(row) for row in img]\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "def flatten_image(img):\n",
    "    \"\"\"\n",
    "    takes in an (m, n) numpy array and flattens it \n",
    "    into an array of shape (1, m * n)\n",
    "    \"\"\"\n",
    "    s = img.shape[0] * img.shape[1]\n",
    "    img_wide = img.reshape(1, s)\n",
    "    return img_wide[0]\n",
    "\n",
    "img_dir = \"/home/rogue1/Documents/cats_dogs/train/\"\n",
    "images = [img_dir+ f for f in os.listdir(img_dir)]\n",
    "labels = [\"dog\" if \"dog\" in f.split('/')[-1] else \"cat\" for f in images]\n",
    "\n",
    "data = []\n",
    "for image in images:\n",
    "    img = img_to_matrix(image)\n",
    "    img = flatten_image(img)\n",
    "    data.append(img)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Binary data\n",
    "np.save('data.npy', data)\n",
    "\n",
    "#Human readable data\n",
    "np.savetxt('data.txt', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***********************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verbose=False\n",
    "filename='/home/rogue1/Documents/cats_dogs/train/cat.6319.jpg'\n",
    "img = PIL.Image.open(filename)\n",
    "if verbose==True:\n",
    "    print (\"changing size from %s to %s\" % (str(img.size), str(STANDARD_SIZE)))\n",
    "img = img.resize(STANDARD_SIZE)\n",
    "img = list(img.getdata())\n",
    "#img = map(list, img)\n",
    "#img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = img.shape[0] * img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flist=os.listdir('/home/rogue1/Documents/cats_dogs/train')\n",
    "\n",
    "id_=[]\n",
    "imgarr_=np.array([])\n",
    "imgarr_= imgarr_.resize((250,250))\n",
    "for fl in flist:\n",
    "    image_path = '/home/rogue1/Documents/cats_dogs/train/' + fl\n",
    "    img = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "    img = img.resize((250,250),PIL.Image.ANTIALIAS)\n",
    "    imgarr = np.array(img)\n",
    "    imgarr_ = np.concatenate((imgarr,imgarr_),axis=1)   \n",
    "    id_.append(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgarr_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(imgarr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgarr_=np.array(imgarr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(imgarr_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file='/home/rogue1/Documents/cats_dogs/train/cat.0.jpg'\n",
    "\n",
    "image_path = '/home/rogue1/Documents/cats_dogs/train/cat.0.jpg'\n",
    "img = PIL.Image.open(image_path).convert(\"RGB\")\n",
    "img = img.resize((250,250),PIL.Image.ANTIALIAS)\n",
    "imgarr = np.array(img).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(imgarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2=np.ravel(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directory to store the downloaded data.\n",
    "data_dir = \"inception/\"\n",
    "\n",
    "# File containing the mappings between class-number and uid. (Downloaded)\n",
    "path_uid_to_cls = \"imagenet_2012_challenge_label_map_proto.pbtxt\"\n",
    "\n",
    "# File containing the mappings between uid and string. (Downloaded)\n",
    "path_uid_to_name = \"imagenet_synset_to_human_label_map.txt\"\n",
    "\n",
    "# File containing the TensorFlow graph definition. (Downloaded)\n",
    "path_graph_def = \"classify_image_graph_def.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Inception:\n",
    "    \"\"\"\n",
    "    The Inception model is a Deep Neural Network which has already been\n",
    "    trained for classifying images into 1000 different categories.\n",
    "\n",
    "    When you create a new instance of this class, the Inception model\n",
    "    will be loaded and can be used immediately without training.\n",
    "\n",
    "    The Inception model can also be used for Transfer Learning.\n",
    "    \"\"\"\n",
    "\n",
    "    # Name of the tensor for feeding the input image as jpeg.\n",
    "    tensor_name_input_jpeg = \"DecodeJpeg/contents:0\"\n",
    "\n",
    "    # Name of the tensor for feeding the decoded input image.\n",
    "    # Use this for feeding images in other formats than jpeg.\n",
    "    tensor_name_input_image = \"DecodeJpeg:0\"\n",
    "\n",
    "    # Name of the tensor for the resized input image.\n",
    "    # This is used to retrieve the image after it has been resized.\n",
    "    tensor_name_resized_image = \"ResizeBilinear:0\"\n",
    "\n",
    "    # Name of the tensor for the output of the softmax-classifier.\n",
    "    # This is used for classifying images with the Inception model.\n",
    "    tensor_name_softmax = \"softmax:0\"\n",
    "\n",
    "    # Name of the tensor for the unscaled outputs of the softmax-classifier (aka. logits).\n",
    "    tensor_name_softmax_logits = \"softmax/logits:0\"\n",
    "\n",
    "    # Name of the tensor for the output of the Inception model.\n",
    "    # This is used for Transfer Learning.\n",
    "    tensor_name_transfer_layer = \"pool_3:0\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Mappings between class-numbers and class-names.\n",
    "        # Used to print the class-name as a string e.g. \"horse\" or \"plant\".\n",
    "        self.name_lookup = NameLookup()\n",
    "\n",
    "        # Now load the Inception model from file. The way TensorFlow\n",
    "        # does this is confusing and requires several steps.\n",
    "\n",
    "        # Create a new TensorFlow computational graph.\n",
    "        self.graph = tf.Graph()\n",
    "\n",
    "        # Set the new graph as the default.\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            # TensorFlow graphs are saved to disk as so-called Protocol Buffers\n",
    "            # aka. proto-bufs which is a file-format that works on multiple\n",
    "            # platforms. In this case it is saved as a binary file.\n",
    "\n",
    "            # Open the graph-def file for binary reading.\n",
    "            path = os.path.join(data_dir, path_graph_def)\n",
    "            with tf.gfile.FastGFile(path, 'rb') as file:\n",
    "                # The graph-def is a saved copy of a TensorFlow graph.\n",
    "                # First we need to create an empty graph-def.\n",
    "                graph_def = tf.GraphDef()\n",
    "\n",
    "                # Then we load the proto-buf file into the graph-def.\n",
    "                graph_def.ParseFromString(file.read())\n",
    "\n",
    "                # Finally we import the graph-def to the default TensorFlow graph.\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "                # Now self.graph holds the Inception model from the proto-buf file.\n",
    "\n",
    "        # Get the output of the Inception model by looking up the tensor\n",
    "        # with the appropriate name for the output of the softmax-classifier.\n",
    "        self.y_pred = self.graph.get_tensor_by_name(self.tensor_name_softmax)\n",
    "\n",
    "        # Get the unscaled outputs for the Inception model (aka. softmax-logits).\n",
    "        self.y_logits = self.graph.get_tensor_by_name(self.tensor_name_softmax_logits)\n",
    "\n",
    "        # Get the tensor for the resized image that is input to the neural network.\n",
    "        self.resized_image = self.graph.get_tensor_by_name(self.tensor_name_resized_image)\n",
    "\n",
    "        # Get the tensor for the last layer of the graph, aka. the transfer-layer.\n",
    "        self.transfer_layer = self.graph.get_tensor_by_name(self.tensor_name_transfer_layer)\n",
    "\n",
    "        # Get the number of elements in the transfer-layer.\n",
    "        self.transfer_len = self.transfer_layer.get_shape()[3]\n",
    "\n",
    "        # Create a TensorFlow session for executing the graph.\n",
    "        self.session = tf.Session(graph=self.graph)\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Call this function when you are done using the Inception model.\n",
    "        It closes the TensorFlow session to release its resources.\n",
    "        \"\"\"\n",
    "\n",
    "        self.session.close()\n",
    "\n",
    "    def _write_summary(self, logdir='summary/'):\n",
    "        \"\"\"\n",
    "        Write graph to summary-file so it can be shown in TensorBoard.\n",
    "\n",
    "        This function is used for debugging and may be changed or removed in the future.\n",
    "\n",
    "        :param logdir:\n",
    "            Directory for writing the summary-files.\n",
    "\n",
    "        :return:\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        writer = tf.train.SummaryWriter(logdir=logdir, graph=self.graph)\n",
    "        writer.close()\n",
    "\n",
    "    def _create_feed_dict(self, image_path=None, image=None):\n",
    "        \"\"\"\n",
    "        Create and return a feed-dict with an image.\n",
    "\n",
    "        :param image_path:\n",
    "            The input image is a jpeg-file with this file-path.\n",
    "\n",
    "        :param image:\n",
    "            The input image is a 3-dim array which is already decoded.\n",
    "            The pixels MUST be values between 0 and 255 (float or int).\n",
    "\n",
    "        :return:\n",
    "            Dict for feeding to the Inception graph in TensorFlow.\n",
    "        \"\"\"\n",
    "\n",
    "        if image is not None:\n",
    "            # Image is passed in as a 3-dim array that is already decoded.\n",
    "            feed_dict = {self.tensor_name_input_image: image}\n",
    "\n",
    "        elif image_path is not None:\n",
    "            # Read the jpeg-image as an array of bytes.\n",
    "            image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "\n",
    "            # Image is passed in as a jpeg-encoded image.\n",
    "            feed_dict = {self.tensor_name_input_jpeg: image_data}\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Either image or image_path must be set.\")\n",
    "\n",
    "        return feed_dict\n",
    "\n",
    "    def classify(self, image_path=None, image=None):\n",
    "        \"\"\"\n",
    "        Use the Inception model to classify a single image.\n",
    "\n",
    "        The image will be resized automatically to 299 x 299 pixels,\n",
    "        see the discussion in the Python Notebook for Tutorial #07.\n",
    "\n",
    "        :param image_path:\n",
    "            The input image is a jpeg-file with this file-path.\n",
    "\n",
    "        :param image:\n",
    "            The input image is a 3-dim array which is already decoded.\n",
    "            The pixels MUST be values between 0 and 255 (float or int).\n",
    "\n",
    "        :return:\n",
    "            Array of floats (aka. softmax-array) indicating how likely\n",
    "            the Inception model thinks the image is of each given class.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a feed-dict for the TensorFlow graph with the input image.\n",
    "        feed_dict = self._create_feed_dict(image_path=image_path, image=image)\n",
    "\n",
    "        # Execute the TensorFlow session to get the predicted labels.\n",
    "        pred = self.session.run(self.y_pred, feed_dict=feed_dict)\n",
    "\n",
    "        # Reduce the array to a single dimension.\n",
    "        pred = np.squeeze(pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def get_resized_image(self, image_path=None, image=None):\n",
    "        \"\"\"\n",
    "        Input an image to the Inception model and return\n",
    "        the resized image. The resized image can be plotted so\n",
    "        we can see what the neural network sees as its input.\n",
    "\n",
    "        :param image_path:\n",
    "            The input image is a jpeg-file with this file-path.\n",
    "\n",
    "        :param image:\n",
    "            The input image is a 3-dim array which is already decoded.\n",
    "            The pixels MUST be values between 0 and 255 (float or int).\n",
    "\n",
    "        :return:\n",
    "            A 3-dim array holding the image.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a feed-dict for the TensorFlow graph with the input image.\n",
    "        feed_dict = self._create_feed_dict(image_path=image_path, image=image)\n",
    "\n",
    "        # Execute the TensorFlow session to get the predicted labels.\n",
    "        resized_image = self.session.run(self.resized_image, feed_dict=feed_dict)\n",
    "\n",
    "        # Remove the 1st dimension of the 4-dim tensor.\n",
    "        resized_image = resized_image.squeeze(axis=0)\n",
    "\n",
    "        # Scale pixels to be between 0.0 and 1.0\n",
    "        resized_image = resized_image.astype(float) / 255.0\n",
    "\n",
    "        return resized_image\n",
    "\n",
    "    def print_scores(self, pred, k=10, only_first_name=True):\n",
    "        \"\"\"\n",
    "        Print the scores (or probabilities) for the top-k predicted classes.\n",
    "\n",
    "        :param pred:\n",
    "            Predicted class-labels returned from the predict() function.\n",
    "\n",
    "        :param k:\n",
    "            How many classes to print.\n",
    "\n",
    "        :param only_first_name:\n",
    "            Some class-names are lists of names, if you only want the first name,\n",
    "            then set only_first_name=True.\n",
    "\n",
    "        :return:\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get a sorted index for the pred-array.\n",
    "        idx = pred.argsort()\n",
    "\n",
    "        # The index is sorted lowest-to-highest values. Take the last k.\n",
    "        top_k = idx[-k:]\n",
    "\n",
    "        # Iterate the top-k classes in reversed order (i.e. highest first).\n",
    "        for cls in reversed(top_k):\n",
    "            # Lookup the class-name.\n",
    "            name = self.name_lookup.cls_to_name(cls=cls, only_first_name=only_first_name)\n",
    "\n",
    "            # Predicted score (or probability) for this class.\n",
    "            score = pred[cls]\n",
    "\n",
    "            # Print the score and class-name.\n",
    "            print(\"{0:>6.2%} : {1}\".format(score, name))\n",
    "        return score, name\n",
    "\n",
    "    def transfer_values(self, image_path=None, image=None):\n",
    "        \"\"\"\n",
    "        Calculate the transfer-values for the given image.\n",
    "        These are the values of the last layer of the Inception model before\n",
    "        the softmax-layer, when inputting the image to the Inception model.\n",
    "\n",
    "        The transfer-values allow us to use the Inception model in so-called\n",
    "        Transfer Learning for other data-sets and different classifications.\n",
    "\n",
    "        It may take several hours or more to calculate the transfer-values\n",
    "        for all images in a data-set. It is therefore useful to cache the\n",
    "        results using the function transfer_values_cache() below.\n",
    "\n",
    "        :param image_path:\n",
    "            The input image is a jpeg-file with this file-path.\n",
    "\n",
    "        :param image:\n",
    "            The input image is a 3-dim array which is already decoded.\n",
    "            The pixels MUST be values between 0 and 255 (float or int).\n",
    "\n",
    "        :return:\n",
    "            The transfer-values for those images.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create a feed-dict for the TensorFlow graph with the input image.\n",
    "        feed_dict = self._create_feed_dict(image_path=image_path, image=image)\n",
    "\n",
    "        # Use TensorFlow to run the graph for the Inception model.\n",
    "        # This calculates the values for the last layer of the Inception model\n",
    "        # prior to the softmax-classification, which we call transfer-values.\n",
    "        transfer_values = self.session.run(self.transfer_layer, feed_dict=feed_dict)\n",
    "\n",
    "        # Reduce to a 1-dim array.\n",
    "        transfer_values = np.squeeze(transfer_values)\n",
    "\n",
    "        return transfer_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NameLookup:\n",
    "    \"\"\"\n",
    "    Used for looking up the name associated with a class-number.\n",
    "    This is used to print the name of a class instead of its number,\n",
    "    e.g. \"plant\" or \"horse\".\n",
    "\n",
    "    Maps between:\n",
    "    - cls is the class-number as an integer between 1 and 1000 (inclusive).\n",
    "    - uid is a class-id as a string from the ImageNet data-set, e.g. \"n00017222\".\n",
    "    - name is the class-name as a string, e.g. \"plant, flora, plant life\"\n",
    "\n",
    "    There are actually 1008 output classes of the Inception model\n",
    "    but there are only 1000 named classes in these mapping-files.\n",
    "    The remaining 8 output classes of the model should not be used.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Mappings between uid, cls and name are dicts, where insertions and\n",
    "        # lookup have O(1) time-usage on average, but may be O(n) in worst case.\n",
    "        self._uid_to_cls = {}   # Map from uid to cls.\n",
    "        self._uid_to_name = {}  # Map from uid to name.\n",
    "        self._cls_to_uid = {}   # Map from cls to uid.\n",
    "\n",
    "        # Read the uid-to-name mappings from file.\n",
    "        path = os.path.join(data_dir, path_uid_to_name)\n",
    "        with open(file=path, mode='r') as file:\n",
    "            # Read all lines from the file.\n",
    "            lines = file.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                # Remove newlines.\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "\n",
    "                # Split the line on tabs.\n",
    "                elements = line.split(\"\\t\")\n",
    "\n",
    "                # Get the uid.\n",
    "                uid = elements[0]\n",
    "\n",
    "                # Get the class-name.\n",
    "                name = elements[1]\n",
    "\n",
    "                # Insert into the lookup-dict.\n",
    "                self._uid_to_name[uid] = name\n",
    "\n",
    "        # Read the uid-to-cls mappings from file.\n",
    "        path = os.path.join(data_dir, path_uid_to_cls)\n",
    "        with open(file=path, mode='r') as file:\n",
    "            # Read all lines from the file.\n",
    "            lines = file.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                # We assume the file is in the proper format,\n",
    "                # so the following lines come in pairs. Other lines are ignored.\n",
    "\n",
    "                if line.startswith(\"  target_class: \"):\n",
    "                    # This line must be the class-number as an integer.\n",
    "\n",
    "                    # Split the line.\n",
    "                    elements = line.split(\": \")\n",
    "\n",
    "                    # Get the class-number as an integer.\n",
    "                    cls = int(elements[1])\n",
    "\n",
    "                elif line.startswith(\"  target_class_string: \"):\n",
    "                    # This line must be the uid as a string.\n",
    "\n",
    "                    # Split the line.\n",
    "                    elements = line.split(\": \")\n",
    "\n",
    "                    # Get the uid as a string e.g. \"n01494475\"\n",
    "                    uid = elements[1]\n",
    "\n",
    "                    # Remove the enclosing \"\" from the string.\n",
    "                    uid = uid[1:-2]\n",
    "\n",
    "                    # Insert into the lookup-dicts for both ways between uid and cls.\n",
    "                    self._uid_to_cls[uid] = cls\n",
    "                    self._cls_to_uid[cls] = uid\n",
    "\n",
    "    def uid_to_cls(self, uid):\n",
    "        \"\"\"\n",
    "        Return the class-number as an integer for the given uid-string.\n",
    "        \"\"\"\n",
    "\n",
    "        return self._uid_to_cls[uid]\n",
    "\n",
    "    def uid_to_name(self, uid, only_first_name=False):\n",
    "        \"\"\"\n",
    "        Return the class-name for the given uid string.\n",
    "\n",
    "        Some class-names are lists of names, if you only want the first name,\n",
    "        then set only_first_name=True.\n",
    "        \"\"\"\n",
    "\n",
    "        # Lookup the name from the uid.\n",
    "        name = self._uid_to_name[uid]\n",
    "\n",
    "        # Only use the first name in the list?\n",
    "        if only_first_name:\n",
    "            name = name.split(\",\")[0]\n",
    "\n",
    "        return name\n",
    "\n",
    "    def cls_to_name(self, cls, only_first_name=False):\n",
    "        \"\"\"\n",
    "        Return the class-name from the integer class-number.\n",
    "\n",
    "        Some class-names are lists of names, if you only want the first name,\n",
    "        then set only_first_name=True.\n",
    "        \"\"\"\n",
    "\n",
    "        # Lookup the uid from the cls.\n",
    "        uid = self._cls_to_uid[cls]\n",
    "\n",
    "        # Lookup the name from the uid.\n",
    "        name = self.uid_to_name(uid=uid, only_first_name=only_first_name)\n",
    "\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Inception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputlist=[]\n",
    "\n",
    "def classify(image_path):\n",
    "    # Display the image.\n",
    "    #display(Image(image_path))\n",
    "\n",
    "    # Use the Inception model to classify the image.\n",
    "    pred = model.classify(image_path=image_path)\n",
    "\n",
    "    # Print the scores and names for the top-10 predictions.\n",
    "    #model.print_scores(pred=pred, k=1, only_first_name=True)\n",
    "    outputlist.append(model.print_scores(pred=pred, k=1, only_first_name=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of Domestic dog sysnet\n",
    "#http://www.image-net.org/api/text/wordnet.structure.hyponym?wnid=n02084071&full=1\n",
    "\n",
    "#list of domestic cat sysnet\n",
    "#http://www.image-net.org/api/text/wordnet.structure.hyponym?wnid=n02121808&full=1\n",
    "\n",
    "#http://image-net.org/archive/words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordnet=pd.read_csv('wordnet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "flist=os.listdir('/home/rogue1/Documents/cats_dogs/train')\n",
    "\n",
    "key=[]\n",
    "\n",
    "for fl in flist:\n",
    "    image_path = '/home/rogue1/Documents/cats_dogs/train/' + fl\n",
    "    classify(image_path)\n",
    "    key.append(fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=pd.DataFrame(outputlist)\n",
    "output.columns=['prob','wnid_words']\n",
    "output=pd.merge(output,wordnet,on='wnid_words',how='left')\n",
    "output['key']=pd.DataFrame(key)\n",
    "output['key']=output['key'].str.replace('dog.','')\n",
    "output['key']=output['key'].str.replace('cat.','')\n",
    "output['key']=output['key'].str.replace('.jpg','')\n",
    "output.to_csv('output.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
